//! Codex ä½¿ç”¨é‡æœåŠ¡
//!
//! è§£æ Codex JSONL æ—¥å¿—æ–‡ä»¶ï¼Œè®¡ç®—æ»šåŠ¨çª—å£ä½¿ç”¨é‡ç»Ÿè®¡

use crate::core::error::Result;
use chrono::{DateTime, Duration, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs::File;
use std::io::{BufRead, BufReader};
use std::path::PathBuf;

/// Codex ä½¿ç”¨é‡è®°å½•
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CodexUsageRecord {
    /// ä¼šè¯ ID
    pub session_id: String,
    /// æ—¶é—´æˆ³
    pub timestamp: DateTime<Utc>,
    /// è¾“å…¥ tokens
    pub input_tokens: u64,
    /// è¾“å‡º tokens
    pub output_tokens: u64,
    /// æ¨¡å‹åç§°
    pub model: Option<String>,
}

/// Codex ä½¿ç”¨é‡ç»Ÿè®¡
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct CodexUsageStats {
    /// æ€»è¾“å…¥ tokens
    pub total_input_tokens: u64,
    /// æ€»è¾“å‡º tokens
    pub total_output_tokens: u64,
    /// æ€»è¯·æ±‚æ•°
    pub total_requests: u64,
    /// çª—å£å¼€å§‹æ—¶é—´
    pub window_start: Option<DateTime<Utc>>,
    /// çª—å£ç»“æŸæ—¶é—´
    pub window_end: Option<DateTime<Utc>>,
}

impl CodexUsageStats {
    /// æ€» tokens
    #[allow(dead_code)]
    pub fn total_tokens(&self) -> u64 {
        self.total_input_tokens + self.total_output_tokens
    }
}

/// æ»šåŠ¨çª—å£ä½¿ç”¨é‡
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct CodexRollingUsage {
    /// 5å°æ—¶çª—å£ç»Ÿè®¡
    pub five_hour: CodexUsageStats,
    /// 7å¤©çª—å£ç»Ÿè®¡
    pub seven_day: CodexUsageStats,
    /// å…¨éƒ¨æ—¶é—´ç»Ÿè®¡
    pub all_time: CodexUsageStats,
    /// æŒ‰æ¨¡å‹åˆ†ç»„çš„ç»Ÿè®¡
    pub by_model: HashMap<String, CodexUsageStats>,
}

/// JSONL äº‹ä»¶ç»“æ„ (æ ¹æ® Codex æ—¥å¿—æ ¼å¼)
#[derive(Debug, Deserialize)]
struct JsonlEvent {
    /// äº‹ä»¶ç±»å‹ (ä¿ç•™ç”¨äºè¿‡æ»¤)
    #[serde(rename = "type")]
    #[allow(dead_code)]
    event_type: Option<String>,
    timestamp: Option<String>,
    session_id: Option<String>,
    #[serde(default)]
    usage: Option<JsonlUsage>,
    model: Option<String>,
}

#[derive(Debug, Deserialize, Default)]
struct JsonlUsage {
    #[serde(default)]
    input_tokens: u64,
    #[serde(default)]
    output_tokens: u64,
}

/// Codex ä½¿ç”¨é‡æœåŠ¡
pub struct CodexUsageService {
    /// Codex é…ç½®ç›®å½•
    codex_dir: PathBuf,
}

impl CodexUsageService {
    /// åˆ›å»ºæ–°çš„æœåŠ¡å®ä¾‹
    pub fn new(codex_dir: PathBuf) -> Self {
        Self { codex_dir }
    }

    /// è·å–æ—¥å¿—ç›®å½•
    fn logs_dir(&self) -> PathBuf {
        self.codex_dir.join("logs")
    }

    /// è§£ææ‰€æœ‰ JSONL æ—¥å¿—æ–‡ä»¶
    pub fn parse_all_logs(&self) -> Result<Vec<CodexUsageRecord>> {
        let logs_dir = self.logs_dir();
        if !logs_dir.exists() {
            return Ok(Vec::new());
        }

        let mut records = Vec::new();

        // è¯»å–æ‰€æœ‰ .jsonl æ–‡ä»¶
        let entries = std::fs::read_dir(&logs_dir)?;

        for entry in entries.flatten() {
            let path = entry.path();
            if path.extension().is_some_and(|ext| ext == "jsonl")
                && let Ok(file_records) = self.parse_jsonl_file(&path)
            {
                records.extend(file_records);
            }
        }

        // æŒ‰æ—¶é—´æ’åº
        records.sort_by(|a, b| a.timestamp.cmp(&b.timestamp));

        Ok(records)
    }

    /// è§£æå•ä¸ª JSONL æ–‡ä»¶
    fn parse_jsonl_file(&self, path: &PathBuf) -> Result<Vec<CodexUsageRecord>> {
        let file = File::open(path)?;

        let reader = BufReader::new(file);
        let mut records = Vec::new();

        for line in reader.lines() {
            let line = match line {
                Ok(l) => l,
                Err(_) => continue,
            };

            if line.trim().is_empty() {
                continue;
            }

            // è§£æ JSON
            let event: JsonlEvent = match serde_json::from_str(&line) {
                Ok(e) => e,
                Err(_) => continue,
            };

            // åªå¤„ç†æœ‰ usage æ•°æ®çš„äº‹ä»¶
            if let Some(usage) = event.usage
                && (usage.input_tokens > 0 || usage.output_tokens > 0)
            {
                // è§£ææ—¶é—´æˆ³
                let timestamp = event
                    .timestamp
                    .as_ref()
                    .and_then(|ts| DateTime::parse_from_rfc3339(ts).ok())
                    .map(|dt| dt.with_timezone(&Utc))
                    .unwrap_or_else(Utc::now);

                records.push(CodexUsageRecord {
                    session_id: event.session_id.unwrap_or_default(),
                    timestamp,
                    input_tokens: usage.input_tokens,
                    output_tokens: usage.output_tokens,
                    model: event.model,
                });
            }
        }

        Ok(records)
    }

    /// è®¡ç®—æ»šåŠ¨çª—å£ä½¿ç”¨é‡
    pub fn compute_rolling_usage(&self) -> Result<CodexRollingUsage> {
        let records = self.parse_all_logs()?;
        let now = Utc::now();

        let five_hours_ago = now - Duration::hours(5);
        let seven_days_ago = now - Duration::days(7);

        let mut rolling = CodexRollingUsage::default();

        for record in &records {
            // å…¨éƒ¨æ—¶é—´
            Self::add_to_stats(&mut rolling.all_time, record);

            // 7å¤©çª—å£
            if record.timestamp >= seven_days_ago {
                Self::add_to_stats(&mut rolling.seven_day, record);
            }

            // 5å°æ—¶çª—å£
            if record.timestamp >= five_hours_ago {
                Self::add_to_stats(&mut rolling.five_hour, record);
            }

            // æŒ‰æ¨¡å‹åˆ†ç»„
            if let Some(model) = &record.model {
                let model_stats = rolling
                    .by_model
                    .entry(model.clone())
                    .or_insert_with(CodexUsageStats::default);
                Self::add_to_stats(model_stats, record);
            }
        }

        // è®¾ç½®çª—å£æ—¶é—´
        rolling.five_hour.window_start = Some(five_hours_ago);
        rolling.five_hour.window_end = Some(now);
        rolling.seven_day.window_start = Some(seven_days_ago);
        rolling.seven_day.window_end = Some(now);

        if let Some(first) = records.first() {
            rolling.all_time.window_start = Some(first.timestamp);
        }
        rolling.all_time.window_end = Some(now);

        Ok(rolling)
    }

    /// æ·»åŠ è®°å½•åˆ°ç»Ÿè®¡
    fn add_to_stats(stats: &mut CodexUsageStats, record: &CodexUsageRecord) {
        stats.total_input_tokens += record.input_tokens;
        stats.total_output_tokens += record.output_tokens;
        stats.total_requests += 1;
    }

    /// æ ¼å¼åŒ– tokens æ•°é‡ (å¸¦ K/M åç¼€)
    pub fn format_tokens(tokens: u64) -> String {
        if tokens >= 1_000_000 {
            format!("{:.1}M", tokens as f64 / 1_000_000.0)
        } else if tokens >= 1_000 {
            format!("{:.1}K", tokens as f64 / 1_000.0)
        } else {
            tokens.to_string()
        }
    }

    /// è·å–ä½¿ç”¨é‡æ‘˜è¦æ–‡æœ¬
    #[allow(dead_code)]
    pub fn get_usage_summary(&self) -> Result<String> {
        let rolling = self.compute_rolling_usage()?;

        let mut summary = String::new();
        summary.push_str("ğŸ“Š Codex ä½¿ç”¨é‡ç»Ÿè®¡\n\n");

        summary.push_str(&format!(
            "5å°æ—¶çª—å£: {} tokens ({} è¾“å…¥ / {} è¾“å‡º) - {} è¯·æ±‚\n",
            Self::format_tokens(rolling.five_hour.total_tokens()),
            Self::format_tokens(rolling.five_hour.total_input_tokens),
            Self::format_tokens(rolling.five_hour.total_output_tokens),
            rolling.five_hour.total_requests
        ));

        summary.push_str(&format!(
            "7å¤©çª—å£:   {} tokens ({} è¾“å…¥ / {} è¾“å‡º) - {} è¯·æ±‚\n",
            Self::format_tokens(rolling.seven_day.total_tokens()),
            Self::format_tokens(rolling.seven_day.total_input_tokens),
            Self::format_tokens(rolling.seven_day.total_output_tokens),
            rolling.seven_day.total_requests
        ));

        summary.push_str(&format!(
            "å…¨éƒ¨æ—¶é—´:  {} tokens ({} è¾“å…¥ / {} è¾“å‡º) - {} è¯·æ±‚\n",
            Self::format_tokens(rolling.all_time.total_tokens()),
            Self::format_tokens(rolling.all_time.total_input_tokens),
            Self::format_tokens(rolling.all_time.total_output_tokens),
            rolling.all_time.total_requests
        ));

        if !rolling.by_model.is_empty() {
            summary.push_str("\næŒ‰æ¨¡å‹ç»Ÿè®¡:\n");
            for (model, stats) in &rolling.by_model {
                summary.push_str(&format!(
                    "  {}: {} tokens - {} è¯·æ±‚\n",
                    model,
                    Self::format_tokens(stats.total_tokens()),
                    stats.total_requests
                ));
            }
        }

        Ok(summary)
    }
}

#[cfg(test)]
mod tests {
    #![allow(clippy::unwrap_used)]
    use super::*;
    use tempfile::TempDir;

    fn create_test_service() -> (CodexUsageService, TempDir) {
        let temp_dir = TempDir::new().unwrap();
        let service = CodexUsageService::new(temp_dir.path().to_path_buf());
        (service, temp_dir)
    }

    #[test]
    fn test_empty_logs() {
        let (service, _temp) = create_test_service();
        let records = service.parse_all_logs().unwrap();
        assert!(records.is_empty());
    }

    #[test]
    fn test_format_tokens() {
        assert_eq!(CodexUsageService::format_tokens(500), "500");
        assert_eq!(CodexUsageService::format_tokens(1500), "1.5K");
        assert_eq!(CodexUsageService::format_tokens(1_500_000), "1.5M");
    }

    #[test]
    fn test_parse_jsonl_with_usage() {
        let (service, temp_dir) = create_test_service();

        // åˆ›å»º logs ç›®å½•
        let logs_dir = temp_dir.path().join("logs");
        std::fs::create_dir_all(&logs_dir).unwrap();

        // åˆ›å»ºæµ‹è¯• JSONL æ–‡ä»¶
        let jsonl_content = r#"{"type":"response","timestamp":"2026-01-15T10:00:00Z","session_id":"sess-1","usage":{"input_tokens":100,"output_tokens":50},"model":"gpt-4"}
{"type":"response","timestamp":"2026-01-15T11:00:00Z","session_id":"sess-1","usage":{"input_tokens":200,"output_tokens":100},"model":"gpt-4"}
{"type":"other","timestamp":"2026-01-15T12:00:00Z"}
"#;
        std::fs::write(logs_dir.join("test.jsonl"), jsonl_content).unwrap();

        let records = service.parse_all_logs().unwrap();
        assert_eq!(records.len(), 2);
        assert_eq!(records[0].input_tokens, 100);
        assert_eq!(records[0].output_tokens, 50);
        assert_eq!(records[1].input_tokens, 200);
        assert_eq!(records[1].output_tokens, 100);
    }

    #[test]
    fn test_compute_rolling_usage() {
        let (service, temp_dir) = create_test_service();

        // åˆ›å»º logs ç›®å½•
        let logs_dir = temp_dir.path().join("logs");
        std::fs::create_dir_all(&logs_dir).unwrap();

        // åˆ›å»ºæµ‹è¯•æ•°æ® - ä½¿ç”¨å½“å‰æ—¶é—´
        let now = Utc::now();
        let recent = now - Duration::hours(1);

        let jsonl_content = format!(
            r#"{{"type":"response","timestamp":"{}","session_id":"sess-1","usage":{{"input_tokens":100,"output_tokens":50}},"model":"gpt-4"}}
"#,
            recent.to_rfc3339()
        );
        std::fs::write(logs_dir.join("test.jsonl"), jsonl_content).unwrap();

        let rolling = service.compute_rolling_usage().unwrap();
        assert_eq!(rolling.five_hour.total_requests, 1);
        assert_eq!(rolling.five_hour.total_input_tokens, 100);
        assert_eq!(rolling.five_hour.total_output_tokens, 50);
        assert_eq!(rolling.seven_day.total_requests, 1);
        assert_eq!(rolling.all_time.total_requests, 1);
    }

    #[test]
    fn test_usage_stats_total_tokens() {
        let stats = CodexUsageStats {
            total_input_tokens: 100,
            total_output_tokens: 50,
            total_requests: 1,
            window_start: None,
            window_end: None,
        };
        assert_eq!(stats.total_tokens(), 150);
    }
}
