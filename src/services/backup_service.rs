// ğŸ§¹ å¤‡ä»½æœåŠ¡
// å°è£…å¤‡ä»½æ¸…ç†ç›¸å…³çš„ä¸šåŠ¡é€»è¾‘

use crate::core::error::{CcrError, Result};
use std::fs;
use std::path::PathBuf;
use std::time::{Duration, SystemTime};
use tokio::fs as async_fs;

/// ğŸ§¹ æ¸…ç†ç»“æœ
#[derive(Debug, Clone)]
pub struct CleanResult {
    pub deleted_count: usize,
    pub skipped_count: usize,
    pub total_size: u64,
}

#[derive(Debug, Clone)]
#[allow(dead_code)]
pub struct BackupFileInfo {
    pub path: PathBuf,
    pub size: u64,
    pub modified: SystemTime,
}

/// ğŸ§¹ å¤‡ä»½æœåŠ¡
///
/// å°è£…å¤‡ä»½æ–‡ä»¶æ¸…ç†ç›¸å…³çš„ä¸šåŠ¡é€»è¾‘
pub struct BackupService {
    backup_dir: PathBuf,
}

impl BackupService {
    /// ğŸ—ï¸ åˆ›å»ºæ–°çš„å¤‡ä»½æœåŠ¡
    ///
    /// # Arguments
    /// - `backup_dir` - å¤‡ä»½ç›®å½•è·¯å¾„
    pub fn new(backup_dir: PathBuf) -> Self {
        Self { backup_dir }
    }

    /// ğŸ  ä½¿ç”¨é»˜è®¤å¤‡ä»½ç›®å½•åˆ›å»ºæœåŠ¡
    ///
    /// é»˜è®¤ç›®å½•: ~/.claude/backups
    pub fn with_default() -> Result<Self> {
        let home =
            dirs::home_dir().ok_or_else(|| CcrError::ConfigError("æ— æ³•è·å–ç”¨æˆ·ä¸»ç›®å½•".into()))?;
        let backup_dir = home.join(".claude").join("backups");
        Ok(Self::new(backup_dir))
    }

    /// ğŸ§¹ æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶
    ///
    /// # Arguments
    /// - `days` - ä¿ç•™å¤©æ•°(åˆ é™¤ N å¤©å‰çš„æ–‡ä»¶)
    /// - `dry_run` - æ¨¡æ‹Ÿè¿è¡Œ(ä¸å®é™…åˆ é™¤)
    ///
    /// # Returns
    /// æ¸…ç†ç»“æœ(åˆ é™¤æ•°é‡ã€è·³è¿‡æ•°é‡ã€é‡Šæ”¾ç©ºé—´)
    pub fn clean_old_backups(&self, days: u64, dry_run: bool) -> Result<CleanResult> {
        if !self.backup_dir.exists() {
            return Ok(CleanResult {
                deleted_count: 0,
                skipped_count: 0,
                total_size: 0,
            });
        }

        let cutoff_time = SystemTime::now() - Duration::from_secs(days * 24 * 60 * 60);
        self.scan_and_clean(cutoff_time, dry_run)
    }

    /// ğŸ§¹ å¼‚æ­¥æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶
    pub async fn clean_old_backups_async(&self, days: u64, dry_run: bool) -> Result<CleanResult> {
        let exists = async_fs::try_exists(&self.backup_dir)
            .await
            .map_err(|e| CcrError::ConfigError(format!("æ£€æŸ¥å¤‡ä»½ç›®å½•å¤±è´¥: {}", e)))?;
        if !exists {
            return Ok(CleanResult {
                deleted_count: 0,
                skipped_count: 0,
                total_size: 0,
            });
        }

        let cutoff_time = SystemTime::now() - Duration::from_secs(days * 24 * 60 * 60);
        self.scan_and_clean_async(cutoff_time, dry_run).await
    }

    #[allow(dead_code)]
    pub fn scan_backup_directory(&self) -> Result<Vec<BackupFileInfo>> {
        use rayon::prelude::*;

        if !self.backup_dir.exists() {
            return Ok(Vec::new());
        }

        let entries: Vec<_> = fs::read_dir(&self.backup_dir)
            .map_err(|e| CcrError::ConfigError(format!("è¯»å–å¤‡ä»½ç›®å½•å¤±è´¥: {}", e)))?
            .filter_map(|e| e.ok())
            .collect();

        let mut backups: Vec<BackupFileInfo> = entries
            .par_iter()
            .filter_map(|entry| {
                let path = entry.path();

                if !path.is_file() || path.extension()?.to_str()? != "bak" {
                    return None;
                }

                let metadata = fs::metadata(&path).ok()?;
                let modified = metadata.modified().ok()?;

                Some(BackupFileInfo {
                    path,
                    size: metadata.len(),
                    modified,
                })
            })
            .collect();

        backups.sort_by(|a, b| b.modified.cmp(&a.modified));
        Ok(backups)
    }

    /// ğŸ” æ‰«æå¹¶æ¸…ç†å¤‡ä»½æ–‡ä»¶
    fn scan_and_clean(&self, cutoff_time: SystemTime, dry_run: bool) -> Result<CleanResult> {
        let mut result = CleanResult {
            deleted_count: 0,
            skipped_count: 0,
            total_size: 0,
        };

        let entries = fs::read_dir(&self.backup_dir)
            .map_err(|e| CcrError::ConfigError(format!("è¯»å–å¤‡ä»½ç›®å½•å¤±è´¥: {}", e)))?;

        for entry in entries {
            let entry =
                entry.map_err(|e| CcrError::ConfigError(format!("è¯»å–ç›®å½•é¡¹å¤±è´¥: {}", e)))?;
            let path = entry.path();

            // åªå¤„ç† .bak æ–‡ä»¶
            if !path.is_file() || path.extension().and_then(|s| s.to_str()) != Some("bak") {
                continue;
            }

            let metadata = fs::metadata(&path)
                .map_err(|e| CcrError::ConfigError(format!("è¯»å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥: {}", e)))?;

            let modified_time = metadata
                .modified()
                .map_err(|e| CcrError::ConfigError(format!("è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´å¤±è´¥: {}", e)))?;

            if modified_time < cutoff_time {
                // æ–‡ä»¶è¶…è¿‡æŒ‡å®šå¤©æ•°,éœ€è¦åˆ é™¤
                let file_size = metadata.len();

                if !dry_run {
                    fs::remove_file(&path)
                        .map_err(|e| CcrError::ConfigError(format!("åˆ é™¤æ–‡ä»¶å¤±è´¥: {}", e)))?;
                }

                result.deleted_count += 1;
                result.total_size += file_size;
            } else {
                // æ–‡ä»¶è¾ƒæ–°,ä¿ç•™
                result.skipped_count += 1;
            }
        }

        Ok(result)
    }

    /// ğŸ” å¼‚æ­¥æ‰«æå¹¶æ¸…ç†å¤‡ä»½æ–‡ä»¶
    async fn scan_and_clean_async(
        &self,
        cutoff_time: SystemTime,
        dry_run: bool,
    ) -> Result<CleanResult> {
        let mut result = CleanResult {
            deleted_count: 0,
            skipped_count: 0,
            total_size: 0,
        };

        let mut entries = async_fs::read_dir(&self.backup_dir)
            .await
            .map_err(|e| CcrError::ConfigError(format!("è¯»å–å¤‡ä»½ç›®å½•å¤±è´¥: {}", e)))?;

        while let Some(entry) = entries
            .next_entry()
            .await
            .map_err(|e| CcrError::ConfigError(format!("è¯»å–ç›®å½•é¡¹å¤±è´¥: {}", e)))?
        {
            let path = entry.path();

            if !path.is_file() || path.extension().and_then(|s| s.to_str()) != Some("bak") {
                continue;
            }

            let metadata = async_fs::metadata(&path)
                .await
                .map_err(|e| CcrError::ConfigError(format!("è¯»å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥: {}", e)))?;

            let modified_time = metadata
                .modified()
                .map_err(|e| CcrError::ConfigError(format!("è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´å¤±è´¥: {}", e)))?;

            if modified_time < cutoff_time {
                let file_size = metadata.len();

                if !dry_run {
                    async_fs::remove_file(&path)
                        .await
                        .map_err(|e| CcrError::ConfigError(format!("åˆ é™¤æ–‡ä»¶å¤±è´¥: {}", e)))?;
                }

                result.deleted_count += 1;
                result.total_size += file_size;
            } else {
                result.skipped_count += 1;
            }
        }

        Ok(result)
    }

    /// ğŸ“ è·å–å¤‡ä»½ç›®å½•è·¯å¾„
    pub fn backup_dir(&self) -> &PathBuf {
        &self.backup_dir
    }
}

#[cfg(test)]
#[allow(clippy::unwrap_used)]
mod tests {
    use super::*;
    use std::fs::File;
    use std::io::Write;
    use tempfile::tempdir;

    #[test]
    fn test_backup_service_clean() {
        let temp_dir = tempdir().unwrap();
        let backup_dir = temp_dir.path().to_path_buf();

        // åˆ›å»ºæµ‹è¯•å¤‡ä»½æ–‡ä»¶
        let old_file = backup_dir.join("old.bak");
        let new_file = backup_dir.join("new.bak");
        let other_file = backup_dir.join("other.txt");

        File::create(&old_file).unwrap().write_all(b"old").unwrap();
        File::create(&new_file).unwrap().write_all(b"new").unwrap();
        File::create(&other_file)
            .unwrap()
            .write_all(b"other")
            .unwrap();

        // è®¾ç½®æ—§æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´ä¸º 10 å¤©å‰
        let old_time = SystemTime::now() - Duration::from_secs(10 * 24 * 60 * 60);
        filetime::set_file_mtime(&old_file, filetime::FileTime::from_system_time(old_time))
            .unwrap();

        let service = BackupService::new(backup_dir);

        // æ¸…ç† 7 å¤©å‰çš„æ–‡ä»¶(dry run)
        let result = service.clean_old_backups(7, true).unwrap();
        assert_eq!(result.deleted_count, 1); // old.bak åº”è¯¥è¢«æ ‡è®°åˆ é™¤
        assert_eq!(result.skipped_count, 1); // new.bak åº”è¯¥è¢«ä¿ç•™
        assert!(old_file.exists()); // dry run ä¸åº”å®é™…åˆ é™¤

        // å®é™…æ¸…ç†
        let result = service.clean_old_backups(7, false).unwrap();
        assert_eq!(result.deleted_count, 1);
        assert!(!old_file.exists()); // åº”è¯¥è¢«åˆ é™¤
        assert!(new_file.exists()); // åº”è¯¥ä¿ç•™
        assert!(other_file.exists()); // é .bak æ–‡ä»¶åº”è¯¥ä¿ç•™
    }

    #[test]
    fn test_backup_service_scan() {
        let temp_dir = tempdir().unwrap();
        let backup_dir = temp_dir.path().to_path_buf();

        // åˆ›å»ºå¤šä¸ªå¤‡ä»½æ–‡ä»¶
        for i in 0..5 {
            let filename = format!("backup{}.bak", i);
            File::create(backup_dir.join(&filename))
                .unwrap()
                .write_all(format!("content{}", i).as_bytes())
                .unwrap();
        }

        let service = BackupService::new(backup_dir);
        let backups = service.scan_backup_directory().unwrap();

        assert_eq!(backups.len(), 5);
        // éªŒè¯æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        for i in 0..backups.len() - 1 {
            assert!(backups[i].modified >= backups[i + 1].modified);
        }
    }
}
